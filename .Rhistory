# It is the same as standard seviation. The above command brings the sqaure-root of variance
# which is the standard deviation.
median(rivers)
?fivenum
barplot(table(state.division), las=2)
getOption("defaultpackage")
getOption("defaultPackage")
get("defaultPackages")
getOption("defaultPackages")
x <- 3*7
print(x)
urnsamples(1:3, size = 2, replace = TRUE, ordered = TRUE)
rolldie <- function(times, nsides = 6, makespace = FALSE){
res <- expand.grid(rep(list(seq(nsides)), times))
names(res) <- c(paste(rep("X", times), 1:times, sep = ""))
if (makespace) res$probs <- 1/nrow(res)
return(res)
}
subset(rolldie(3), X1+X2 == 6)
subset(rolldie(2), X1+X2 == 6)
subset(rolldie(3), X1+X2+X3 > 16)
cards <- function (jokers = FALSE, makespace = FALSE){
x <- c(2:10, "J", "Q", "K", "A")
y <- c("Club", "Diamond", "Heart", "Spade")
res <- expand.grid(rank = x, suit = y)
if (jokers) {
jokers <- data.frame(rank = c("Joker", "Joker"), suit = c(NA, NA))
res <- rbind(res, jokers)
}
if (makespace) res$probs <- 1/nrow(res)
return(res)
}
S=expand.grid(die1=1:6, die2=1:6)
S=transform(S, dies=rowSums(S))
s
S
dies{1:6, size=2, replace = True, ordered = True}
dies(1:6, size=2, replace = True, ordered = True)
S(1:6, size=2, replace = True, ordered = True)
S(1:6, size=2, replace = True, ordered = True)
x = c(0,1,2,3)
p = c(*p)
si=sum(x-mu)^2*p)
si=sum((x-mu)^2*p)
p = c(1/8, 3/8, 3/8, 1/8)
s1
Pbinom(10, 10, 0.8)
pbinom(10, 10, 0.8)
dbinom(10, 10, 0.8)
X=dbinom(10, 10, 0.8)
X
X0=dpois(0, lambda=1)
X1=dpois(1, lambda=1)
X2=dpois(2, lambda=1)
X3=dpois(3, lambda=1)
X4=dpois(4, lambda=1)
X5=dpois(5, lambda=1)
X6=dpois(6, lambda=1)
Xsum=sum(X0,X1,X2,X3,X4,X5,X6)
Xsum
X0=dpois(0, lambda=1)
X1=dpois(1, lambda=1)
X2=dpois(2, lambda=1)
X3=dpois(3, lambda=1)
X4=dpois(4, lambda=1)
X5=dpois(5, lambda=1)
X6=dpois(6, lambda=1)
Xsum=sum(X0,X1,X2,X3,X4,X5,X6)
Xsum
?pmorm
?pnorm
x <- "5"
class(x)
names(v) <- c("a", "b", "c")
v <- c(1, 2, 3)
v
values <- c(5, 3, 1)
titles <- c("x", "y", "z")
names(values) <- titles
values
browseURL("www.google.com", browser = "C:\Program Files (x86)\Google\Chrome\Application\chrome.exe")
browseURL("www.google.com", browser = "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe")
browseURL("www.google.com", browser = "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe")
mybrowser$open()
mybrowser<- browseURL("www.google.com", browser = "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe")
mybrowser$open()
url="www.google.com"
driver = "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe"
driver.get(url)
url="www.google.com"
driver = "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe"
driver.get(url)
url="www.google.com"
driver = "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe"
browseURL(url, browser= driver)
url="www.google.com"
driver = "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe"
browseURL(url, browser= driver)
search = "//input[@class="gLFyf gsfi"]"
driver.search.click
library(data.table)
library(XML)
url="www.google.com"
driver = "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe"
browseURL(url, browser= driver)
search = "//input[@class="gLFyf gsfi"]"
xpath?
library?
his?
?xpath
??xpath
?browseURL
?browserText
url="www.google.com"
driver = "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe"
browseURL(url, browser= driver)
search = "//input[@class="gLFyf gsfi"]"
url="www.google.com"
driver = "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe"
browseURL(url, browser= driver)
search="//input[@class="gLFyf gsfi"]"
url="www.google.com"
driver = "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe"
browseURL(url, browser= driver)
# search="//input[@class="gLFyf gsfi"]"
?DRIVER
?driver
?click
?enter
read.csv(file.choose(), header=T)
install.packages("readxl")
# Loading
library("readxl")
# xls files
my_data <- read_excel("my_file.xls")
# xlsx files
my_data <- read_excel("my_file.xlsx")
install.packages("readxl")
# Loading
library("readxl")
# xls files
my_data <- read_excel("C://Users//Vinod//Desktop//OPR//Week 3//OPR_601_Exam_1.xlsx")
# xlsx files
#my_data <- read_excel("my_file.xlsx")
url="www.google.com"
driver = "C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe"
browseURL(url, browser= driver)
# search="//input[@class="gLFyf gsfi"]"
read.csv(file.choose(), header=T)
# Loading
library("readxl")
# xls files
my_data <- read_excel("C://Users//Vinod//Desktop//OPR//Week 3//OPR_601_Exam_1.xlsx")
# xlsx files
#my_data <- read_excel("my_file.xlsx")
# Loading
library("readxl")
# xls files
my_data <- read_excel("C://Users//Vinod//Desktop//OPR//Week 3//OPR_601_Exam_1.xlsx")
# xlsx files
#my_data <- read_excel("my_file.xlsx")
my_data
library("readxl")
# xls files
my_data <- read_excel("C://Users//Vinod//Desktop//OPR//Week 3//OPR_601_Exam_1.xlsx", sep=",")
# xlsx files
#my_data <- read_excel("my_file.xlsx")
my_data
library("readxl")
# xls files
my_data <- read_excel("C://Users//Vinod//Desktop//OPR//Week 3//OPR_601_Exam_1.xlsx", sheet= "Q1 - a", sep=",")
# xlsx files
#my_data <- read_excel("my_file.xlsx")
my_data
f <- function(x) 3*x^2
integrate(f, lower = 0.14, upper = 0.71)
?norm
norm(mean = 3500, sd = 500)
norm(mean = "3500", sd = "500")
norm(mean=3500, sd=500)
pnorm(3100, mean=3500, sd=500)
dnorm(3100, mean=3500, sd=500)
?dnorm
pnorm(900, mean=3500, sd=500)
pnorm(3)
pnorm(3)
pnorm(3)
pnorm(42, 35, 6)
pnorm(3)
pnorm(42, mean=35, sd=6)
punif(0.9, min=0, max=1)
pnorm(3)
pnorm(42, mean=35, sd=6)
runif(0.9, min=0, max=1)
pnorm(3)
pnorm(42, mean=35, sd=6)
punif(0.9, min=0, max=1)
pnorm(3)
pnorm(42, mean=35, sd=6)
punif(0.9, min=0, max=1)
pexp(3, lambda=2) - pexp(1, lambda=2)
?pexp
pnorm(3)
pnorm(42, mean=35, sd=6)
punif(0.9, min=0, max=1)
pexp(3, rate = 2) - pexp(1, lambda=2)
pnorm(3)
pnorm(42, mean=35, sd=6)
punif(0.9, min=0, max=1)
pexp(3, rate = 2) - pexp(1, rate = 2)
?pchisq
curve(dchisq(x, df = 3), from = 0, to = 20, ylab = "y")
ind <- c(4, 5, 10, 15)
for (i in ind) curve(dchisq(x, df = i), 0, 20, add = TRUE)
curve(dchisq(x, df = 2), from = 6.5, to = 7.5, ylab = "y")
ind <- c(6.7, 6.9, 7.1, 7.3)
for (i in ind) curve(dchisq(x, df = i), 6.5, 7.5, add = TRUE)
curve(pchisq(x, df = 2), from = 6.5, to = 7.5, ylab = "y")
ind <- c(6.7, 6.9, 7.1, 7.3)
for (i in ind) curve(pchisq(x, df = i), 6.5, 7.5, add = TRUE)
curve(pchisq(x, df = 2), from = 6.5, to = 7.5, ylab = "y")
ind <- c(6.6, 6.8, 7.0, 7.2, 7.4)
for (i in ind) curve(pchisq(x, df = i), 6.5, 7.5, add = TRUE)
?Chisquare
pnorm(3)
pnorm(42, mean=35, sd=6)
punif(0.9, min=0, max=1)
pexp(3, rate = 2) - pexp(1, rate = 2)
pchisq(7.5, df=2) - pchisq(6.5, df=2)
pnorm(3)
pnorm(42, mean=35, sd=6)
punif(0.9, min=0, max=1)
pexp(3, rate = 2) - pexp(1, rate = 2)
pchisq(7.5, df=2) - pchisq(6.5, df=2)
pbinom(10, size=10, prob=0.8)
pexp(4, rate=1/4)
dexp(4, rate=1/4)
1-pnorm(3100, mean=3500, sd=500)
#a
pnorm(3)
#b
pnorm(42, mean=35, sd=6)
#c
punif(0.9, min=0, max=1)
#d
pexp(3, rate = 2) - pexp(1, rate = 2)
#e
pchisq(7.5, df=2) - pchisq(6.5, df=2)
#f
pbinom(10, size=10, prob=0.8)
?rgamma
pnorm(3200, 3500, 500) - pnorm(3000, 3500, 500)
pnorm(-3000,3500,500) + pnorm(3200,3500,500) - 1
pnorm(3200, 3500, 500) - pnorm(3000, 3500, 500)
pnorm(3000,3500,500) + pnorm(3200,3500,500) - 1
pnorm(3200,3500,500) - pnorm(3000,3500,500)
- pnorm(3000,3500,500) + pnorm(3200,3500,500) - 1
pnorm(3200,3500,500) - pnorm(3000,3500,500)
pnorm(-3000,3500,500) + pnorm(3200,3500,500) - 1
pnorm(3200,3500,500) - pnorm(3000,3500,500)
pnorm(-3000,3500,500) + pnorm(3200,3500,500) - 1
pnorm(-3000,3500,500) - pnorm(-3200,3500,500)
pnorm(3200,3500,500) - pnorm(3000,3500,500)
pnorm(3200,3500,500))-(1-pnorm(3000,3500,500)
(1-pnorm(-3200,3500,500))-(1-pnorm(-3000,3500,500))
pnorm(3200,3500,500) - pnorm(3000,3500,500)
(pnorm(3200,3500,500))-(1-pnorm(3000,3500,500))
(1-pnorm(-3200,3500,500))-(1-pnorm(-3000,3500,500))
pnorm(3200,3500,500) - pnorm(3000,3500,500)
(pnorm(3200,3500,500))-(1-pnorm(-3000,3500,500))
(1-pnorm(-3200,3500,500))-(1-pnorm(-3000,3500,500))
pnorm(3200,3500,500) - pnorm(3000,3500,500)
(pnorm(3200,3500,500))-(1-pnorm(-3000,3500,500))
(1-pnorm(3200,3500,500))-(1-pnorm(3000,3500,500))
pnorm(3200,3500,500) - pnorm(3000,3500,500)
(pnorm(3200,3500,500))-(1-pnorm(-3000,3500,500))
(1-pnorm(3000,3500,500))-(1-pnorm(3200,3500,500))
pnorm(3200,3500,500) - pnorm(3000,3500,500)
(pnorm(3200,3500,500))-(1-pnorm(3000,3500,500))
(1-pnorm(3000,3500,500))-(1-pnorm(3200,3500,500))
pnorm(3200,3500,500) - pnorm(3000,3500,500)
(1-pnorm(3000,3500,500))-pnorm(3200,3500,500)
(1-pnorm(3000,3500,500))-(1-pnorm(3200,3500,500))
1-pexp(4, rate = 1/4)
1-pexp(4, rate = 1/4)
?dgamma
pgamma(0, shape=2, rate=4)
pgamma(1, shape=2, rate=4)
pgamma(2, shape=2, rate=4)
pgamma(3, shape=2, rate=4)
rgamma(0, shape=2, rate=4)
rgamma(1, shape=2, rate=4)
rgamma(2, shape=2, rate=4)
rgamma(3, shape=2, rate=4)
1-pnorm(3)
1-pnorm(3)
pnorm(42, mean=35, sd=6)
punif(0.9, min=0, max=1)
pexp(3, rate = 2) - pexp(1, rate = 2)
pchisq(7.5, df=2) - pchisq(6.5, df=2)
pbinom(10, size=10, prob=0.8)
1-pnorm(3)
1-pnorm(42, mean=35, sd=6)
punif(0.9, min=0, max=1)
pexp(3, rate = 2) - pexp(1, rate = 2)
pchisq(7.5, df=2) - pchisq(6.5, df=2)
pbinom(10, size=10, prob=0.8)
1-pnorm(3)
1-pnorm(42, mean=35, sd=6)
punif(0.9, min=0, max=1)
pexp(3, rate = 2) - pexp(1, rate = 2)
pchisq(7.5, df=2) - pchisq(6.5, df=2)
pbinom(10, size=10, prob=0.8)
1-pnorm(3)
1-pnorm(42, mean=35, sd=6)
punif(0.9, min=0, max=1)
pexp(3, rate = 2) - pexp(1, rate = 2)
pchisq(7.5, df=2) - pchisq(6.5, df=2)
dbinom(10, size=10, prob=0.8)
#a
1-pnorm(3)
#b
1-pnorm(42, mean=35, sd=6)
#c
punif(0.9, min=0, max=1)
#d
pexp(3, rate = 2) - pexp(1, rate = 2)
#e
pchisq(7.5, df=2) - pchisq(6.5, df=2)
#f
dbinom(10, size=10, prob=0.8)
dgamma(0, shape=2, rate=4)
dgamma(1, shape=2, rate=4)
dgamma(2, shape=2, rate=4)
dgamma(3, shape=2, rate=4)
rgamma(1000, shape=2, rate=4)
l = rgamma(1000, shape=2, rate=4)
distribution_mean = 2/4
distribution_variance = 2/(4^2)
distribution_mean == l
l = rgamma(1000, shape=2, rate=4)
distribution_mean = 2/4
distribution_variance = 2/(4^2)
distribution_variance == l
pgamma(0, shape=2, rate=4)
pgamma(1, shape=2, rate=4)
pgamma(2, shape=2, rate=4)
pgamma(3, shape=2, rate=4)
pgamma(0:3, Shape=2, rate=4)
pgamma(0:3,2,4)
pgamma(0:3,2,4)
browseURL("www.facebook.com", browser="C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe")
library(XML)
install(XML)
install.packages("XML")
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
plot(pressure)
browseURL("www.facebook.com", browser="C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe")
browseURL("www.google.com", browser="C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe")
browseURL("www.google.com", browser="C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe")
Xpath_Search = "//input[@class="gLFyf gsfi"]"
?xpathApply
install.packages("xpath")
?replicate
afinn <- get_sentiments("afinn")
#install.packages(c("ggplot2", "e1071", "caret", "quanteda", "irlba", "randomForest"))
#install.packages("tm")
#install.packages("wordcloud")
#install.packages("RColorBrewer")
#install.packages(c("tidytext","dplyr"))
#install.packages(c("tidyverse","stringr"))
#install.packages('stringdist')
#install.packages('NLP')
library(tidytext)
library(dplyr)
library(RColorBrewer)
library(tm)
library(NLP)
library(tidyverse)
library(wordcloud)
library(stringr)
setwd("C:\\Users\\Vinod\\Desktop\\MIS\\Project")
amazon_review <- read.csv("amazon.csv", stringsAsFactors = FALSE)
names(amazon_review) <- c("Date", "Review")
#amazon_text <- paste(amazon_review$Review, collapse=" ")
amazon_text <- c(amazon_review$Review)
#amazon_text <- str_split(amazon_review$Review, pattern = "\\s+")
class(amazon_text)
#amazon_text<-as.list(amazon_text)
class(amazon_text)
amazon_text[1]
#amazon_text <- as.matrix(amazon_text)
sentiments
afinn <- get_sentiments("afinn")
#bing = data.frame(bing$word,bing$sentiment)
afinn <- as.matrix(afinn)
afinnpos <- c(which(afinn[,2]<100))
afinnposwords <- as.list(afinn[(afinnpos),1])
amazon_source <- VectorSource(amazon_text)
amazon_corpus <- VCorpus(amazon_source)
amazon_corpus <- tm_map(amazon_corpus, content_transformer(tolower))
amazon_corpus <- tm_map(amazon_corpus, removePunctuation)
#amazon_corpus <- tm_map(amazon_corpus,stripWhitespace)
amazon_corpus <- tm_map(amazon_corpus, removeWords, stopwords("english"))
amazon_text<- as.list(scan(text = amazon_text[4], what=""))
#amazon_source <- VectorSource(amazon_text)
#amazon_corpus <- VCorpus(amazon_source)
w <- intersect(amazon_text,afinnposwords)
e <- match(w,afinnposwords)
w
e
score <- c(as.numeric(afinn[e,2]))
score
totalscore <- sum(score)
totalscore
#for (i in 1:5){
#amazon_text <- as.list(str_split(amazon_text[i], pattern = "\\s+"))
#amazon_source <- VectorSource(amazon_text)
#amazon_corpus <- VCorpus(amazon_source)
#match <- intersect(amazon_corpus,afinnposwords)
#next()
#}
#grep(afinnposwords, amazon_text[1])
#intersect(amazon_text, bingposwords)
#bingposwords <- paste(bingposwords, collapse=" ")
#bingposwords <- str_split(bingposwords, pattern = "\\s+")
bingneg <- c(which(bing[,2]=="negative"))
bingnegwords <- bing[(bingneg),1]
length(bingposwords)
bing <- get_sentiments("bing")
#bing = data.frame(bing$word,bing$sentiment)
bing <- as.matrix(bing)
bingpos <- c(which(bing[,2]=="positive"))
bingposwords <- bing[(bingpos),1]
#bingposwords <- paste(bingposwords, collapse=" ")
#bingposwords <- str_split(bingposwords, pattern = "\\s+")
bingneg <- c(which(bing[,2]=="negative"))
bingnegwords <- bing[(bingneg),1]
length(bingposwords)
nrc <- get_sentiments("nrc")
#nrc = data.frame(nrc$word,nrc$sentiment)
nrc <- as.matrix(nrc)
nrcpos <- c(which((nrc[,2]=="positive")|(nrc[,2]=="trust")|(nrc[,2]=="joy")))
nrcposwords <- nrc[(nrcpos),1]
nrcneg <- c(which((nrc[,2]=="negative")|(nrc[,2]=="fear")|(nrc[,2]=="anger")|(nrc[,2]=="disgust")|(nrc[,2]=="sadness")))
nrcnegwords <- nrc[(nrcneg),1]
amazon_source <- VectorSource(amazon_text)
amazon_corpus <- VCorpus(amazon_source)
amazon_corpus <- tm_map(amazon_corpus, content_transformer(tolower))
amazon_corpus <- tm_map(amazon_corpus, removePunctuation)
amazon_corpus <- tm_map(amazon_corpus,stripWhitespace)
amazon_corpus <- tm_map(amazon_corpus, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(amazon_corpus)
dtm2 <- as.matrix(dtm)
amazon_words <- sort(colSums(dtm2), decreasing = TRUE )
frequency <- data.frame(word = names(amazon_words), freq=amazon_words)
class(amazon_text)
class(bingposwords)
class(bingnegwords)
poswords <- scan('pos.txt',what='character', comment.char=";")
class(poswords)
a<-c(intersect(amazon_text, bingposwords))
a
b<-c(intersect(amazon_text, bingnegwords))
b
c<-c(intersect(amazon_text, nrcposwords))
c
d<-c(intersect(amazon_text, nrcnegwords))
d
positive_words <- c(a, c)
positive_words
negative_words <- c(b, d)
negative_words
sum(!is.na(match (amazon_text, bingposwords)))
sum(!is.na(match (amazon_text, nrcposwords)))
sum(!is.na(match (amazon_text, bingnegwords)))
sum(!is.na(match (amazon_text, nrcnegwords)))
#wordcloud(word[1:100], freq[1:100])
wordcloud(positive_words, min.freq = 1, scale = c(2,1))
barplot(d[5:15,]$freq, las = 2, names.arg = d[5:15,]$word,
col ="lightblue", main ="Most frequent words",
ylab = "Word frequencies")
afinn <- get_sentiments("afinn")
afinn
bing <- get_sentiments("bing")
bing
nrc <- get_sentiments("nrc")
nrc
nrc [5000]
nrc [5000,2]
nrc [50000,2]
nrc [13891,2]
nrc [13890,2]
nrc [12890,2]
nrc [12891,2]
nrc [12891,1]
nrc <- get_sentiments("nrc")
nrc [12889,2]
nrc [12888,2]
nrc [12887,2]
nrc [12891,1]
nrc [12500,1]
nrc [11500,1]
nrc [9500,1]
nrc [5500,1]
nrc [6500,1]
nrc [13891,1]
nrc <- get_sentiments("nrc")
nrc [13500:13600,1:2]
nrc [13500:13600,1:2]
nrc [13550:13600,1:2]
